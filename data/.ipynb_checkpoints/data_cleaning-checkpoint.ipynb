{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarms = pd.read_csv('Alarms_of_the_sensors.csv', sep=None, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>alarm_type</th>\n",
       "      <th>severity</th>\n",
       "      <th>status</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>atm_pm_1_0</th>\n",
       "      <th>atm_pm_2_5</th>\n",
       "      <th>co2</th>\n",
       "      <th>delta</th>\n",
       "      <th>ma</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-10 16:19:48</td>\n",
       "      <td>Sensor_0057</td>\n",
       "      <td>Уровень CO2</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>709</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0013</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1144</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0089</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2474</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0079</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>402</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0068</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>606</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    sensor_id         alarm_type     severity  \\\n",
       "0  2025-11-10 16:19:48  Sensor_0057        Уровень CO2  Критический   \n",
       "1  2025-11-09 05:38:38  Sensor_0013  Потеря соединения  Критический   \n",
       "2  2025-11-09 05:38:38  Sensor_0089  Потеря соединения  Критический   \n",
       "3  2025-11-09 05:38:38  Sensor_0079  Потеря соединения  Критический   \n",
       "4  2025-11-09 05:38:38  Sensor_0068  Потеря соединения  Критический   \n",
       "\n",
       "                        status  Assignee  atm_pm_1_0  atm_pm_2_5   co2  delta  \\\n",
       "0  Сброшенные неподтвержденные         2           0           1   709     38   \n",
       "1  Сброшенные неподтвержденные         0           0           0  1144     27   \n",
       "2  Сброшенные неподтвержденные         0           0           0  2474     28   \n",
       "3  Сброшенные неподтвержденные         0           0           0   402     29   \n",
       "4  Сброшенные неподтвержденные         0           0           0   606     25   \n",
       "\n",
       "   ma  temperature  \n",
       "0   1           27  \n",
       "1   0           30  \n",
       "2   0           27  \n",
       "3   0           27  \n",
       "4   0           27  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'sensor_id', 'alarm_type', 'severity', 'status', 'Assignee',\n",
      "       'atm_pm_1_0', 'atm_pm_2_5', 'co2', 'delta', 'ma', 'temperature'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(alarms.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>alarm_type</th>\n",
       "      <th>severity</th>\n",
       "      <th>status</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>atm_pm_1_0</th>\n",
       "      <th>atm_pm_2_5</th>\n",
       "      <th>co2</th>\n",
       "      <th>delta</th>\n",
       "      <th>ma</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-10 16:19:48</td>\n",
       "      <td>Sensor_0057</td>\n",
       "      <td>Уровень CO2</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>709</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0013</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1144</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0089</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2474</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0079</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>402</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0068</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>606</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    sensor_id         alarm_type     severity  \\\n",
       "0  2025-11-10 16:19:48  Sensor_0057        Уровень CO2  Критический   \n",
       "1  2025-11-09 05:38:38  Sensor_0013  Потеря соединения  Критический   \n",
       "2  2025-11-09 05:38:38  Sensor_0089  Потеря соединения  Критический   \n",
       "3  2025-11-09 05:38:38  Sensor_0079  Потеря соединения  Критический   \n",
       "4  2025-11-09 05:38:38  Sensor_0068  Потеря соединения  Критический   \n",
       "\n",
       "                        status  Assignee  atm_pm_1_0  atm_pm_2_5   co2  delta  \\\n",
       "0  Сброшенные неподтвержденные         2           0           1   709     38   \n",
       "1  Сброшенные неподтвержденные         0           0           0  1144     27   \n",
       "2  Сброшенные неподтвержденные         0           0           0  2474     28   \n",
       "3  Сброшенные неподтвержденные         0           0           0   402     29   \n",
       "4  Сброшенные неподтвержденные         0           0           0   606     25   \n",
       "\n",
       "   ma  temperature  \n",
       "0   1           27  \n",
       "1   0           30  \n",
       "2   0           27  \n",
       "3   0           27  \n",
       "4   0           27  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarms = alarms.drop(columns=['Assignee', 'delta'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sensor_id         alarm_type     severity                       status\n",
      "0  Sensor_0057        Уровень CO2  Критический  Сброшенные неподтвержденные\n",
      "1  Sensor_0013  Потеря соединения  Критический  Сброшенные неподтвержденные\n",
      "2  Sensor_0089  Потеря соединения  Критический  Сброшенные неподтвержденные\n",
      "3  Sensor_0079  Потеря соединения  Критический  Сброшенные неподтвержденные\n",
      "4  Sensor_0068  Потеря соединения  Критический  Сброшенные неподтвержденные\n"
     ]
    }
   ],
   "source": [
    "columns_to_show = ['Timestamp', 'sensor_id', 'alarm_type', 'severity', 'status']\n",
    "existing_columns = [col for col in columns_to_show if col in alarms.columns]\n",
    "print(alarms[existing_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Уровень CO2', 'Потеря соединения', 'Курение',\n",
       "       'Высокая концентрация CO2', 'Высокая температура',\n",
       "       'Низкая влажность'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarms['alarm_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Критический'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarms['severity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarms = pd.read_csv('Alarms_of_the_sensors.csv', sep=None, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>alarm_type</th>\n",
       "      <th>severity</th>\n",
       "      <th>status</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>atm_pm_1_0</th>\n",
       "      <th>atm_pm_2_5</th>\n",
       "      <th>co2</th>\n",
       "      <th>delta</th>\n",
       "      <th>ma</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-10 16:19:48</td>\n",
       "      <td>Sensor_0057</td>\n",
       "      <td>Уровень CO2</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>709</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0013</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1144</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0089</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2474</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0079</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>402</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-09 05:38:38</td>\n",
       "      <td>Sensor_0068</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>606</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    sensor_id         alarm_type     severity  \\\n",
       "0  2025-11-10 16:19:48  Sensor_0057        Уровень CO2  Критический   \n",
       "1  2025-11-09 05:38:38  Sensor_0013  Потеря соединения  Критический   \n",
       "2  2025-11-09 05:38:38  Sensor_0089  Потеря соединения  Критический   \n",
       "3  2025-11-09 05:38:38  Sensor_0079  Потеря соединения  Критический   \n",
       "4  2025-11-09 05:38:38  Sensor_0068  Потеря соединения  Критический   \n",
       "\n",
       "                        status  Assignee  atm_pm_1_0  atm_pm_2_5   co2  delta  \\\n",
       "0  Сброшенные неподтвержденные         2           0           1   709     38   \n",
       "1  Сброшенные неподтвержденные         0           0           0  1144     27   \n",
       "2  Сброшенные неподтвержденные         0           0           0  2474     28   \n",
       "3  Сброшенные неподтвержденные         0           0           0   402     29   \n",
       "4  Сброшенные неподтвержденные         0           0           0   606     25   \n",
       "\n",
       "   ma  temperature  \n",
       "0   1           27  \n",
       "1   0           30  \n",
       "2   0           27  \n",
       "3   0           27  \n",
       "4   0           27  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>alarm_type</th>\n",
       "      <th>severity</th>\n",
       "      <th>status</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>atm_pm_1_0</th>\n",
       "      <th>atm_pm_2_5</th>\n",
       "      <th>co2</th>\n",
       "      <th>delta</th>\n",
       "      <th>ma</th>\n",
       "      <th>temperature</th>\n",
       "      <th>time_utc</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-10 21:19:48+05:00</td>\n",
       "      <td>Sensor_0057</td>\n",
       "      <td>Уровень CO2</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>709</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2025-11-10 16:19:48+00:00</td>\n",
       "      <td>1762791588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-09 10:38:38+05:00</td>\n",
       "      <td>Sensor_0013</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1144</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2025-11-09 05:38:38+00:00</td>\n",
       "      <td>1762666718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-09 10:38:38+05:00</td>\n",
       "      <td>Sensor_0089</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2474</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2025-11-09 05:38:38+00:00</td>\n",
       "      <td>1762666718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-09 10:38:38+05:00</td>\n",
       "      <td>Sensor_0079</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>402</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2025-11-09 05:38:38+00:00</td>\n",
       "      <td>1762666718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-09 10:38:38+05:00</td>\n",
       "      <td>Sensor_0068</td>\n",
       "      <td>Потеря соединения</td>\n",
       "      <td>Критический</td>\n",
       "      <td>Сброшенные неподтвержденные</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>606</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2025-11-09 05:38:38+00:00</td>\n",
       "      <td>1762666718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time    sensor_id         alarm_type     severity  \\\n",
       "0 2025-11-10 21:19:48+05:00  Sensor_0057        Уровень CO2  Критический   \n",
       "1 2025-11-09 10:38:38+05:00  Sensor_0013  Потеря соединения  Критический   \n",
       "2 2025-11-09 10:38:38+05:00  Sensor_0089  Потеря соединения  Критический   \n",
       "3 2025-11-09 10:38:38+05:00  Sensor_0079  Потеря соединения  Критический   \n",
       "4 2025-11-09 10:38:38+05:00  Sensor_0068  Потеря соединения  Критический   \n",
       "\n",
       "                        status  Assignee  atm_pm_1_0  atm_pm_2_5   co2  delta  \\\n",
       "0  Сброшенные неподтвержденные         2           0           1   709     38   \n",
       "1  Сброшенные неподтвержденные         0           0           0  1144     27   \n",
       "2  Сброшенные неподтвержденные         0           0           0  2474     28   \n",
       "3  Сброшенные неподтвержденные         0           0           0   402     29   \n",
       "4  Сброшенные неподтвержденные         0           0           0   606     25   \n",
       "\n",
       "   ma  temperature                  time_utc   timestamp  \n",
       "0   1           27 2025-11-10 16:19:48+00:00  1762791588  \n",
       "1   0           30 2025-11-09 05:38:38+00:00  1762666718  \n",
       "2   0           27 2025-11-09 05:38:38+00:00  1762666718  \n",
       "3   0           27 2025-11-09 05:38:38+00:00  1762666718  \n",
       "4   0           27 2025-11-09 05:38:38+00:00  1762666718  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alarms['time'] = pd.to_datetime(alarms['time'], utc=True)\n",
    "\n",
    "# Convert from its current timezone to UTC+5 if needed\n",
    "# If you know the timestamps are already UTC+5 logically but in UTC format:\n",
    "alarms['time'] = alarms['time'].dt.tz_convert('Etc/GMT-5')\n",
    "\n",
    "# Then convert to pure UTC for database consistency\n",
    "alarms['time_utc'] = alarms['time'].dt.tz_convert('UTC')\n",
    "\n",
    "# Create UNIX timestamp column (seconds)\n",
    "alarms['timestamp'] = alarms['time_utc'].astype('int64') // 10**9\n",
    "\n",
    "alarms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp  atm_pm_1_0  atm_pm_2_5  co2    hum   temp\n",
      "0  1762611990           3           6  400  36.79  26.99\n",
      "1  1762612000           3           6  402  36.80  26.98\n",
      "2  1762612010           3           5  403  36.81  26.99\n",
      "3  1762612020           3           7  400  36.81  27.01\n",
      "4  1762612030           4           7  404  36.81  27.00\n"
     ]
    }
   ],
   "source": [
    "sensor_ids = [\n",
    "    \"Sensor_0013\",\n",
    "    \"Sensor_0039\",\n",
    "    \"Sensor_0045\",\n",
    "    \"Sensor_0057\",\n",
    "    \"Sensor_0068\",\n",
    "    \"Sensor_0079\",\n",
    "    \"Sensor_0080\",\n",
    "    \"Sensor_0089\"\n",
    "]\n",
    "\n",
    "sensor_data = {}\n",
    "\n",
    "for sensor in sensor_ids:\n",
    "    filename = f\"{sensor}_150_days.csv\"\n",
    "    df = pd.read_csv(filename, sep=None, engine=\"python\")\n",
    "\n",
    "    # Convert timestamp\n",
    "    df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "    df['time'] = df['time'].dt.tz_convert(\"Etc/GMT-5\")\n",
    "    df['time_utc'] = df['time'].dt.tz_convert(\"UTC\")\n",
    "    df['timestamp'] = df['time_utc'].astype(\"int64\") // 10**9\n",
    "\n",
    "    # Drop unwanted columns if they exist\n",
    "    for col in ['delta', 'time', 'time_utc', 'ma']:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    new_order = ['timestamp', 'atm_pm_1_0', 'atm_pm_2_5', 'co2', 'hum', 'temp']\n",
    "    # keep only those columns that exist\n",
    "    new_order = [col for col in new_order if col in df.columns]\n",
    "    df = df[new_order]\n",
    "\n",
    "    # Save into dictionary\n",
    "    sensor_data[sensor] = df\n",
    "\n",
    "# Example access:\n",
    "print(sensor_data[\"Sensor_0057\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lagged_features(df, target_col=\"co2\", n_lags=10, horizon_steps=1):\n",
    "    \"\"\"\n",
    "    df: DataFrame with time column + numeric sensor columns\n",
    "    target_col: which column we want to forecast\n",
    "    n_lags: how many past steps to use as features\n",
    "    horizon_steps: how many steps ahead to forecast (1 = next record)\n",
    "    \"\"\"\n",
    "    df = df.sort_values(\"time\").reset_index(drop=True)\n",
    "    \n",
    "    # Make sure time is datetime (drop tz if needed for simplicity)\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    \n",
    "    # numeric features\n",
    "    feature_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if target_col not in feature_cols:\n",
    "        feature_cols.append(target_col)\n",
    "    \n",
    "    # Build lag features based on target_col\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        df[f\"{target_col}_lag_{lag}\"] = df[target_col].shift(lag)\n",
    "    \n",
    "    # Target is horizon_steps ahead\n",
    "    df[f\"{target_col}_future_{horizon_steps}\"] = df[target_col].shift(-horizon_steps)\n",
    "    \n",
    "    # Drop rows with NaNs created by shifts\n",
    "    df_model = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # X = lag features (+ optionally other numeric features)\n",
    "    lag_cols = [f\"{target_col}_lag_{lag}\" for lag in range(1, n_lags + 1)]\n",
    "    # optionally add other sensors as current-step features\n",
    "    extra_cols = [c for c in feature_cols if c != target_col]\n",
    "    \n",
    "    X = df_model[lag_cols + extra_cols]\n",
    "    y = df_model[f\"{target_col}_future_{horizon_steps}\"]\n",
    "    \n",
    "    return df_model, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Sensor_0013, forecast 1 step ahead): 13.392\n"
     ]
    }
   ],
   "source": [
    "# 1) Load\n",
    "sensor_0013_df = pd.read_csv(\"Sensor_0013_150_days.csv\", sep=None, engine=\"python\")\n",
    "\n",
    "# If your file already has 'timestamp' and 'time_utc' etc, keep at least 'time' and numeric columns\n",
    "# e.g. sensor_0013_df = sensor_0013_df[[\"time\", \"co2\", \"atm_pm_2_5\", \"ma\", \"temp\"]]\n",
    "\n",
    "# 2) Build lagged dataset (using co2 as target, 10 lags, forecast 1 step ahead)\n",
    "df_0013_model, X, y = make_lagged_features(sensor_0013_df, target_col=\"co2\",\n",
    "                                           n_lags=10, horizon_steps=1)\n",
    "\n",
    "# 3) Time-based train/test split (last 20% as test)\n",
    "split_idx = int(len(df_0013_model) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "# 4) Train model\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "# rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"RMSE (Sensor_0013, forecast 1 step ahead): {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    time  co2  co2_pred  residual  drift_flag\n",
      "8338 2025-11-14 10:15:11  506   504.215    -1.785       False\n",
      "8339 2025-11-14 10:15:21  502   495.085    -6.915       False\n",
      "8340 2025-11-14 10:15:31  512   495.750   -16.250       False\n",
      "8341 2025-11-14 10:15:41  515   505.005    -9.995       False\n",
      "8342 2025-11-14 10:15:52  530   513.560   -16.440       False\n"
     ]
    }
   ],
   "source": [
    "# Attach predictions & residuals to the test part of df\n",
    "df_test = df_0013_model.iloc[split_idx:].copy()\n",
    "df_test[\"co2_pred\"] = y_pred\n",
    "df_test[\"residual\"] = df_test[\"co2_pred\"] - df_test[\"co2\"]\n",
    "\n",
    "# Rolling statistics of residuals\n",
    "window = 300  # e.g. 300 points (tune to your frequency)\n",
    "df_test[\"resid_mean\"] = df_test[\"residual\"].rolling(window).mean()\n",
    "df_test[\"resid_std\"] = df_test[\"residual\"].rolling(window).std()\n",
    "\n",
    "# Simple drift/anomaly rule:\n",
    "k = 3  # 3-sigma rule\n",
    "df_test[\"drift_flag\"] = (\n",
    "    (df_test[\"residual\"] - df_test[\"resid_mean\"]).abs() > k * df_test[\"resid_std\"]\n",
    ")\n",
    "\n",
    "print(df_test[[\"time\", \"co2\", \"co2_pred\", \"residual\", \"drift_flag\"]].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 17)) while a minimum of 1 is required by RandomForestRegressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     32\u001b[39m y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n\u001b[32m     34\u001b[39m model = RandomForestRegressor(\n\u001b[32m     35\u001b[39m     n_estimators=\u001b[32m200\u001b[39m,\n\u001b[32m     36\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     37\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     38\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m y_pred = model.predict(X_test)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# FIXED RMSE\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:359\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[32m    372\u001b[39m estimator = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimator)(criterion=\u001b[38;5;28mself\u001b[39m.criterion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 17)) while a minimum of 1 is required by RandomForestRegressor."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "files = [\n",
    "    \"Sensor_0013_150_days.csv\",\n",
    "    \"Sensor_0039_150_days.csv\",\n",
    "    \"Sensor_0045_150_days.csv\",\n",
    "    \"Sensor_0057_150_days.csv\",\n",
    "    \"Sensor_0068_150_days.csv\",\n",
    "    \"Sensor_0079_150_days.csv\",\n",
    "    \"Sensor_0080_150_days.csv\",\n",
    "    \"Sensor_0089_150_days.csv\",\n",
    "]\n",
    "\n",
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for fname in files:\n",
    "    df = pd.read_csv(fname, sep=None, engine=\"python\")\n",
    "    \n",
    "    # Build supervised data (adjust n_lags, target col as needed)\n",
    "    df_model, X, y = make_lagged_features(df,\n",
    "                                          target_col=\"co2\",\n",
    "                                          n_lags=10,\n",
    "                                          horizon_steps=1)\n",
    "    \n",
    "    split_idx = int(len(df_model) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    \n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # FIXED RMSE\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    models[fname] = model\n",
    "    metrics[fname] = rmse\n",
    "\n",
    "print(\"RMSE per file:\")\n",
    "for fname, rmse in metrics.items():\n",
    "    print(f\"{fname}: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 20)\n",
      "Feature rows: 0\n",
      "Target rows: 0\n",
      "Time unique count: 49800\n",
      "Total rows loaded: 50051\n",
      "NaN rows dropped: 50051\n"
     ]
    }
   ],
   "source": [
    "print(df_model.shape)\n",
    "print(\"Feature rows:\", X.shape[0])\n",
    "print(\"Target rows:\", y.shape[0])\n",
    "print(\"Time unique count:\", df[\"time\"].nunique())\n",
    "print(\"Total rows loaded:\", df.shape[0])\n",
    "print(\"NaN rows dropped:\", df.shape[0] - df_model.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
